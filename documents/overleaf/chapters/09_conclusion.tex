\clearpage
\chapter{Conclusion and Future Work}

The purpose of this work was to enable QoS-aware task execution on distributed Node-RED clusters for fog computing environments.
Therefore, a system that dynamically reacts to changes in the fog network had to be designed and implemented in order to achieve the lowest possible service latencies.

Initially, a literature research was conducted to obtain the current state of research about fog computing, QoS, resource allocation and self-adaptive systems.
In the next step, use cases which would benefit from such a system were introduced before describing the technical and theoretical challenges.

Based on the preceding work, a QoS scheduling and resource allocation algorithm was designed and implemented.
However, this algorithm had to be used in a dynamic fog environment.
Therefore, an infrastructure monitoring system was implemented next.
To apply the deployment strategy determined by the algorithm, functionalities for controlling Node-RED instances have been added to the system.

The evaluation has shown that the system is able to dynamically apply varying deployment strategies to the infrastructure depending on the fog environment's current state.
Overall, the results are satisfying, although improvements are possible.\\


The task execution time could not always be estimated reliably, so incorrect decisions by the system are possible.
It was found that the technique used to compare CPUs of different devices is not suitable for this purpose.
The system would benefit from further research on this topic:
How to reliably predict the execution time of different tasks on different devices?
For instance, this could be achieved by implementing a machine learning algorithm which predicts the execution time of a specific module on a specific node based on historical data.

While evaluating the system, the same image was always sent to the object detection service, so the incoming data size was equal throughout all experiments.
However, incoming data may vary in size and content, thus affecting the execution time as well as the transfer time.
The systemâ€™s decision making process could be supported if metadata of incoming data could be predicted by a machine learning algorithm.


Another interesting question is how the system behaves with an increasing amount of nodes.
Since any network connection from one node to another is remeasured at a certain interval, the network may congest if the amount of measurements exceed a certain point because each measurement takes time and utilizes bandwidth that cannot be used by users' service requests during the measurement.
The system could be improved here by checking only certain connections, skipping the ones that are unlikely to be used in a deployment strategy.

Ideally, no network measurements are performed.
This could be realized by another layer on top of the network.
For instance, information about the network's current load could be provided by the routers (gateway routers in particular) that are part of the infrastructure.


The algorithm developed in this thesis is not limited to be used in a Node-RED infrastructure.
For instance, it could also be used to deploy and move Docker containers instead of Node-RED flows.